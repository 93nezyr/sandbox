% ドキュメントクラスの定義
\documentclass[twocolumn, a4j, 10pt, fleqn]{ltjsarticle}

\usepackage{enumitem}
\usepackage{url}
\usepackage{amsmath}
\usepackage[margin=10truemm]{geometry}
\usepackage{graphicx}
\usepackage{caption}

% tcolorbox関連
\usepackage{tcolorbox}
\tcbuselibrary{breakable, skins, theorems}

\captionsetup[figure]{format=plain, labelformat=simple, labelsep=period}

\setlength{\columnseprule}{0.1pt}
% \setlength{\mathindent}{0pt}
\renewcommand{\baselinestretch}{0.8}
\renewcommand{\figurename}{Fig}
\setlength{\textfloatsep}{0pt}

% 部名の変更
\renewcommand{\prepartname}{第}
\renewcommand{\postpartname}{部}
\renewcommand{\thepart}{\arabic{part}}

% 本文開始
\begin{document}

% タイトル設定
\title{Neural Network Loss}
\author{93 san}
\maketitle

% 部・節・項・目
\part{ModelX2}
本部では、各節で説明される問題を解決したNeuralNetworkを提案する.

% 節
\section{DQN-MC loss改善}
DQN-MCでは、学習時にモデルが収束しない時に起こっていると考えられる現象として、以下の二つがあげられる。NeuralNetwork自身は、与えられたサンプルに対して十分に学習が進んでおり、これ以上lossが下がる能力がない状況を前提とする.

\vskip\baselineskip
\noindent
\begin{tcolorbox}[
  colback = white,
  colframe = black,
  fonttitle = \bfseries,
  % enlarge top by = -1em,
  % enlarge bottom by = -4em,
  breakable = true]
  \begin{itemize}
    \item $Q(s_t, a_1)$と$Q(s_t, a_2)$の真の期待値が十分近い場合、各NN更新ステップのミニバッチ学習時に、ミニバッチ内のターゲットの分布の偏りによって、NNが学習している$Q(s_t, a_1)$と$Q(s_t, a_2)$の大小関係が逆転することで、生成されるエピソードが変動する.\label{item:r1}
    \item NNの精度が十分でない場合、本来十分離れているはずの$Q(s_t, a_1)$と$Q(s_t, a_2)$の真の期待値を十分に予測できず、各NN更新ステップのミニバッチ学習時に、$Q(s_t, a_1)$に対する予測の振動幅と、$Q(s_t, a_2)$に対する予測の振動幅が重なることで、$Q(s_t, a_1)$と$Q(s_t, a_2)$の大小関係が逆転し、生成されるエピソードが変動する.\label{item:r2}
  \end{itemize}
\end{tcolorbox}
\noindent
*ただし、$ReplayBuffer$内の各$(s, a)$の組に対するターゲットの期待値が変動しない仮定において.\\
\noindent
*ここで「収束しない」とは、学習中のモデルがgreedyに行動決定した場合でも、生成されるエピソードが変動することを指す.

\vskip\baselineskip
上記の原因二つに対して、改善可能と考えられるのは以下である.

\begin{enumerate}
  \item 報酬関数の変更:\\
        $Q(s_t, a_1)$と$Q(s_t, a_2)$の期待値の差を広げることで、大小関係の逆転を防ぐ. もしくは、完全に各$(s_t, a_k)$に対して、一意の報酬が与えられるような報酬体系にする(DQN-MCでは不可).
  \item NNのloss改善:\label{enum:NNloss}\\
        $Q(s_t, a_1)$と$Q(s_t, a_2)$の期待値が十分に離れていることを前提に、両者の大小関係が逆転しないレベルまでNNのlossを低下させる.
  \item Backup方法の変更:\\
        DQN-MC以外のBackup方法に変更することで、期待値を予測するという学習をやめる.
\end{enumerate}
本節では、上記の\ref{enum:NNloss}について取り組む.

% 項
\subsection{Neural Network Architecture For Decrease loss of ModelX2}
本項では、NeuralNetworkの損失低下について取り組む.
\vskip\baselineskip

% 目
\subsubsection{Ensemble Quantile Regression DQN-MC}
本セクションでは、DQN-MCが期待値を真の目標値として学習することから生じる\ref{item:r1}と、広範で非連続的な状態行動対とターゲットを学習することから生じる\ref{item:r2}を同時に解決する手法を提案する.

まず、NeuralNetworkの更新方法をQuantile Regressionに変更する. これによって真の期待値は近しいが、本来異なるターゲット分布を持つ$Q(s_t, a_1)$と$Q(s_t, a_2)$の行動選択時の関係逆転を防ぐ.

加えて、エージェントが保持するNeuralNetworkを$action space \times N$個にする. ここで、$action$は強化学習における行動を表し、$action space$は時刻$t$でエージェントが実行可能な行動の総数を表す. 本案では、各$action$に対して$N$個のNNが対応することになる. $N$個のNNは状態$s_t$のあるパラメータ$x_{s_t}$をもとに$N$分割された状態空間のみを入力に学習する. 例として、状態$s_t$がパラメータ$x$を持つとした場合、$0 \le x \le 10$の状態は$NN_1$が、$11 \le x \le 20$の状態は$NN_2$が、といったように分割する. これにより広範な状態$s_t$を全て一つの$NN$で学習する必要が無くなり、全体的な$loss$の低減に繋がることを期待する.

ただし、学習中$x$の最大最小値は変動するため、状態の分割方法にも工夫が必要である.
\vskip\baselineskip

状態の分割方法の案を以下のように提案する.

\begin{enumerate}
  \item ハードセッティング:\\
        事前に分割数$N$と、パラメータ$x$に対する分割幅を決めておく.
  \item 
\end{enumerate}

\subsubsection{Accuracy Quantile Regression DQN-MC}
本セクションでは、DQN-MCが期待通りの学習を行えていないことに対する、解決を試みる。

ここで言う、「期待通りでない学習」とは、以下のような状況を指す.

\begin{enumerate}
  \item 任意の分位点の値が、真の値と異なる.
        DQN-MCの場合、学習終盤にGreedyな方策でサンプリングし続けている場合、ほとんどサンプルが同じ報酬値を示す. そのような状況でも、各分位点がその値と異なる値を出力している状況.
  \item 累積分布関数を示すはずの分位点の大小関係が逆転している.
        1,とも関連するが、こちらに関しては各分位点の値が真の値を示せていなくとも、本来累積分布関数を示すはずの各分位点の大小関係が逆転してしまう現象を指す.
\end{enumerate}

\noindent
まず、上記の2,について解決を試みる.

\cite{fzhou}で、分布強化学習における分位点の大小関係の逆転問題について言及されている．

\begin{thebibliography}{99}
  \bibitem{fzhou}
  Zhou, Fan, Jianing Wang, and Xingdong Feng. "Non-crossing quantile regression for distributional reinforcement learning." Advances in neural information processing systems 33 (2020): 15909-15919.
\end{thebibliography}

% 部
\part{ModelX4}

\end{document}